## 消息队列

### 1. 为什么使用消息队列？

消息队列有3个比较核心的使用场景：**解耦**、**异步**、**削峰**

- **解耦**：通过一个 MQ，Pub/Sub 发布订阅消息这么一个模型， 系统之间彻底解耦。传统的软件开发模式，各个模块之间相互调用，每个模块都要时刻关注其他模块的是否更改或者是否挂掉等等。使用消息队列，可以避免模块之间直接调用，将所需共享的数据放在消息队列中，对于新增业务模块，只要对该类消息感兴趣，即可订阅该类消息，对原有系统和业务没有任何影响，降低了系统各个模块的耦合度，提高了系统的可扩展性。

- **异步**：消息队列提供了异步处理机制，在很多时候应用不需要立即处理请求消息，允许应用把一些消息放入MQ中，并不立即处理它，在之后需要的时候再慢慢处理，这样就可以在较短时间内返回响应给请求方。

  （1）3 + 300 + 450 + 200 = 953ms

  <img src="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/mq-3.png?raw=true" alt="mq-3.png" style="zoom:67%;" />

  （2）3 + 5 = 8ms

  <img src="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/mq-4.png?raw=true" alt="mq-4.png" style="zoom:67%;" />

- **削峰**：在访问量骤增的场景下，需要保证应用系统的平稳性，但是这样突发流量并不常见，如果以这类峰值的标准而投放资源的话，那无疑是巨大的浪费。使用消息队列能够使关键组件支撑突发访问压力，不会因为突发的超负荷请求而完全崩溃。消息队列的容量可以配置的很大，如果采用磁盘存储消息，则几乎等于“无限”容量，这样一来，高峰期的消息可以被积压起来，在随后的时间内进行平滑的处理完成，而不至于让系统短时间内无法承载而导致崩溃。在电商网站的秒杀抢购这种突发性流量很强的业务场景中，消息队列的强大缓冲能力可以很好的起到削峰作用。

  

### 2. 消息队列都有什么优缺点？

缺点：

- **系统可用性降低** 一旦MQ发生故障不可用，将会导致与之相关的所有服务崩溃
- **系统复杂度提高** 架构复杂了，业务没有明显的流程线，不好管理
- **一致性问题** 如何保证Consumer在拿到数据后正确运行也是一个问题 

优点：

- **吞吐量提升**：无需等待订阅者处理完成，响应更快速

- **故障隔离**：服务没有直接调用，不存在级联失败问题
- **调用间没有阻塞**，不会造成无效的资源占用
- **耦合度极低**，每个服务都可以灵活插拔，可替换
- **流量削峰**：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件

几种常见MQ的对比：

<table><thead><tr class="firstRow"><th>特性</th><th>ActiveMQ</th><th>RabbitMQ</th><th>RocketMQ</th><th>Kafka</th></tr></thead><tbody><tr><td>单机吞吐量</td><td>万级，比 RocketMQ、Kafka 低一个数量级</td><td>同 ActiveMQ</td><td>10 万级，支撑高吞吐</td><td>10 万级，高吞吐，一般配合大数据类的系统来进行实时数据计算、日志采集等场景</td></tr><tr><td>topic 数量对吞吐量的影响</td><td>&nbsp;</td><td>&nbsp;</td><td>topic 可以达到几百/几千的级别，吞吐量会有较小幅度的下降，这是 RocketMQ 的一大优势，在同等机器下，可以支撑大量的 topic</td><td>topic 从几十到几百个时候，吞吐量会大幅度下降，在同等机器下，Kafka 尽量保证 topic 数量不要过多，如果要支撑大规模的 topic，需要增加更多的机器资源</td></tr><tr><td>时效性</td><td>ms 级</td><td>微秒级，这是 RabbitMQ 的一大特点，延迟最低</td><td>ms 级</td><td>延迟在 ms 级以内</td></tr><tr><td>可用性</td><td>高，基于主从架构实现高可用</td><td>同 ActiveMQ</td><td>非常高，分布式架构</td><td>非常高，分布式，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用</td></tr><tr><td>消息可靠性</td><td>有较低的概率丢失数据</td><td>基本不丢</td><td>经过参数优化配置，可以做到 0 丢失</td><td>同 RocketMQ</td></tr><tr><td>功能支持</td><td>MQ 领域的功能极其完备</td><td>基于 erlang 开发，并发能力很强，性能极好，延时很低</td><td>MQ 功能较为完善，还是分布式的，扩展性好</td><td>功能较为简单，主要支持简单的 MQ 功能，在大数据领域的实时计算以及日志采集被大规模使用</td></tr></tbody></table>

追求可用性：Kafka、 RocketMQ 、RabbitMQ

追求可靠性：RabbitMQ、RocketMQ

追求吞吐能力：RocketMQ、Kafka

追求消息低延迟：RabbitMQ、Kafka



### 3. 消息队列如何保证顺序消费

==参考答案==

在生产中经常会有一些类似报表系统这样的系统，需要做 MySQL 的 binlog 同步。比如订单系统要同步订单表的数据到大数据部门的 MySQL 库中用于报表统计分析，通常的做法是基于 Canal 这样的中间件去监听订单数据库的 binlog，然后把这些 binlog 发送到 MQ 中，再由消费者从 MQ 中获取 binlog 落地到大数据部门的 MySQL 中。

在这个过程中，可能会有对某个订单的增删改操作，比如有三条 binlog 执行顺序是增加、修改、删除。消费者愣是换了顺序给执行成删除、修改、增加，这样能行吗？肯定是不行的。不同的消息队列产品，产生消息错乱的原因，以及解决方案是不同的。下面我们以RabbitMQ、Kafka、RocketMQ为例，来说明保证顺序消费的办法。

**RabbitMQ**：

对于 RabbitMQ 来说，导致上面顺序错乱的原因通常是消费者是集群部署，不同的消费者消费到了同一订单的不同的消息。如消费者A执行了增加，消费者B执行了修改，消费者C执行了删除，但是消费者C执行比消费者B快，消费者B又比消费者A快，就会导致消费 binlog 执行到数据库的时候顺序错乱，本该顺序是增加、修改、删除，变成了删除、修改、增加。

RabbitMQ 的问题是由于不同的消息都发送到了同一个 queue 中，多个消费者都消费同一个 queue 的消息。解决这个问题，我们可以给 RabbitMQ 创建多个 queue，每个消费者固定消费一个 queue 的消息，生产者发送消息的时候，同一个订单号的消息发送到同一个 queue 中，由于同一个 queue 的消息是一定会保证有序的，那么同一个订单号的消息就只会被一个消费者顺序消费，从而保证了消息的顺序性。



### 4. 如何保证消息的可靠性传输？或者说，如何处理消息丢失的问题？

==参考答案==

数据的丢失问题，可能出现在**生产者**、**MQ**、**消费者**中

![rabbitmq-message-lose.png](https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/rabbitmq-message-lose.png?raw=true)

<img src="https://raw.githubusercontent.com/ayifuture0920/java-study/main/pictures/image-20220624113845244.png" alt="image-20220624113845244" style="zoom: 50%;" />

但是问题是，RabbitMQ 事务机制（同步）一搞，基本上吞吐量会下来，因为太耗性能。

#### 4.1 生产者弄丢了数据

- 选择用 RabbitMQ 提供的**事务功能**，就是生产者发送数据之前开启 RabbitMQ 事务，然后发送消息，如果消息没有成功被 RabbitMQ 接收到，那么生产者会收到异常报错，此时就可以回滚事务，然后重试发送消息；如果收到了消息，那么可以提交事务。

- 可以**开启 confirm 模式**，在生产者那里设置开启 confirm 模式之后，你每次写的消息都会分配一个唯一的 id，然后如果写入了 RabbitMQ 中，RabbitMQ 会回传一个 `ack` 消息，表明这个消息 已经投递到`RabbitMQ` 了。如果消息未能投递到`RabbitMQ`，`RabbitMQ` 会回传一个 `nack` 消息，表明消息接收失败，可以重试。而且你可以结合这个机制自己在内存里维护每个消息 id 的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。

**事务机制**和 **`confirm` 机制**最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是 `confirm` 机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息 `RabbitMQ` 接收了之后会异步回调你的一个接口通知你这个消息接收到了。所以一般在生产者这块避免数据丢失，都是用 `confirm` 机制的。

#### 4.2 `RabbitMQ`弄丢了数据

生产者确认可以确保消息投递到 RabbitMQ的交换机中，但是消息发送到 RabbitMQ 以后，如果突然宕机，也可能导致消息丢失。要想确保消息在 RabbitMQ 中安全保存，必须开启消息持久化机制。设置消息持久化到磁盘，设置持久化有两个步骤：

- **设置队列持久化**，这样就可以保证 RabbitMQ 持久化 queue 的元数据，但是它是不会持久化 queue 里的数据的。 *<font color="blue">RabbitMQ 集群元数据是指 RabbitMQ 集群的信息，包括User、Vhost、Queue、Exchange、Binding Key、Permission、Parameter等信息</font>*
- **设置消息持久化**，发送消息的时候将消息的`deliveryMode`设置为2，这样消息就会被设为持久化方式，此时RabbitMQ就会将消息持久化到磁盘上。 必须要同时开启这两个才可以。

而且持久化可以跟生产的 confirm 机制配合起来，只有消息持久化到了磁盘之后，才会通知生产者ack，这样就算是在持久化之前 RabbitMQ 挂了，数据丢了，生产者收不到ack回调也会进行消息重发。

**`RabbitMQ`中交换机、队列和消息都是非持久化的，而`SpringAMQP`中交换机、队列和消息都是持久化的，无需刻意设置。**

#### 4.3 消费者弄丢了数据

RabbitMQ 是**阅后即焚**机制，RabbitMQ 确认消息被消费者消费后会立刻删除。而 RabbitMQ 是通过消费者回执来确认消费者是否成功处理消息的：消费者获取消息后，应该向 RabbitMQ 发送 `ACK` 回执，表明自己已经处理消息。

利用 **RabbitMQ 提供的 `ACK` 机制**：必须关闭 RabbitMQ 的自动 `ACK` ，可以通过一个 api 来调用，然后每次在确保处理完这个消息之后，在代码里手动调用 `ACK`。这样就可以避免消息还没有处理完就 `ACK`。



### 5. 如何避免消息重复投递或重复消费？

==参考答案==

*<font color="blue">正常情况下，消费者在消费消息后，会给消息队列发送一个确认，消息队列接收后就知道消息已经被成功消费了，然后就从队列中删除该消息，也就不会将该消息再发送给其他消费者了。不同消息队列发出的确认消息形式不同，RabbitMQ是通过发送一个ACK确认消息。但是因为网络故障，消费者发出的确认并没有传到消息队列，导致消息队列不知道该消息已经被消费，然后就再次消息发送给了其他消费者，从而造成重复消费的情况。其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。举个例子，假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，不就保留了一条数据？</font>*

重复消费问题的解决思路是：保证消息的唯一性，即使多次传输，也不让消息的多次消费带来影响，也就是保证消息幂等性；幂等性指一个操作执行任意多次所产生的影响均与一次执行的影响相同。

想要保证不重复消费，其实还要结合业务来思考，这里给几个思路：

（1）**改造业务逻辑，使得在重复消费时也不影响最终的结果**。例如对SQL语句： update t1 set money = 150 where id = 1 and money = 100; 做了个前置条件判断，即 money = 100 的情况下才会做更新，更通用的是做个 version 即版本号控制，对比消息中的版本号和数据库中的版本号。


（2）**基于数据库的的唯一主键进行约束**。消费完消息之后，到数据库中做一个 insert 操作，如果出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。

（3）通过记录关键key，当重复消息过来时，先判断下这个key是否已经被处理过了，如果没处理再进行下一步。




- **在消息生产时**，MQ 内部针对每条生产者发送的消息生成一个全局唯一ID，作为去重的依据（消息投递失败并重传），避免重复的消息进入队列；

- **在消息消费时**，要求消息体中必须要有一个 bizId（对于同一业务全局唯一，如支付 ID、订单 ID、帖子 ID 等）作为去重的依据，避免同一条消息被重复消费。



### 6.  消息在什么时候会变成死信？

==参考答案==

消息成为死信的情况：

- 消息被消费者 reject 或者返回 `nack`，并且没有设置重新入队（Requeue）
- 消息超时未消费
- 队列满了

### 7. MQ处理消息失败了怎么办？

==参考答案==

一般生产环境中，都会在使用MQ的时候设计两个队列：一个是**核心业务队列**，一个是**死信队列**。核心业务队列，就是传递业务消息的，另外一个死信队列就是用来处理异常情况的。MQ处理消息失败后，消息就会成为私信，MQ就会把这条消息转入提前设置好的一个死信队列中。监听死信队列的后台线程就从死信队列中取出处理失败的消息，可以自行处理或交由人工处理，进一步提高消息队列的可靠性。死信队列的使用是MQ在生产实践中非常重要的一环，也就是架构设计必须要考虑的。



### 8. 消息基于什么传输？

==参考答案==

由于 TCP 连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ 使用**信道**的方式来传输数据。信道是建立在真实的 TCP 连接内的虚拟连接，且每条 TCP 连接上的信道数量没有限制。



### 9. 多个消费者监听一个队列时，消息如何分发？

==参考答案==

多个消费者绑定到一个队列，同一条消息只会被一个消费者处理。消息默认采用轮询（`Round-Robin`）的方式发送给消费者。也可以通过设置`prefetch`来控制消费者预取的消息数量，从而实现能者多劳。



### 10. 消息怎么路由？

==参考答案==

在`Pub/Sub`模式中，消息提供方将消息投递到交换机中，交通过换机路由到与之绑定的队列中。**Exchange（交换机）只负责转发消息，不具备存储消息的能力**，因此如果没有任何队列与Exchange绑定，或者没有符合路由规则的队列，那么消息会丢失！交换机分为三种：**Fanout**、**Direct**、**Topic**。

- **Fanout**交换机收到消息后，将消息广播到所有绑定的队列上；
- **Direct** 交换机和 **Topic** 交换机与队列的绑定，不能是任意绑定了，而是要指定一个`RoutingKey`（路由key），消息的发送方在向 Exchange 发送消息时，也必须指定消息的 `RoutingKey`，Exchange 不再把消息交给每一个绑定的队列，而是根据消息的`Routing Key`进行判断，只有队列的`Routingkey`与消息的 `Routing key`完全一致，才会接收到消息。`Topic`类型的`Exchange`与`Direct`相比，都是可以根据`RoutingKey`把消息路由到不同的队列。只不过`Topic`类型`Exchange`可以让队列在绑定`Routing key` 的时候使用通配符（`#`：匹配0个或多个词，`*`：匹配恰好1个词）。

### 11. 无法被路由的消息去了哪里？（交换机没有将消息路由到相应的队列要怎么办？）

==参考答案==

无设置的情况下，无法路由（Routing key错误）的消息会被直接丢弃。通过配置`template.mandatory`：定义消息路由失败时的策略。`true`，则调用 ReturnCallback；`false`：则直接丢弃消息。同时搭配`publish-returns`：开启 publish-return 功能，定义 ReturnCallback 。消息投递到交换机了，但是没有路由到队列。publish-return 返回ACK，及路由失败原因，同时可以进行重发消息操作。



### 12. RabbitMQ如何实现延迟队列

==参考答案==

利用TTL（`Time to Live`，消息存活时间），加上死信交换机实现延迟队列。RabbitMQ 的官方也推出了一个插件 DelayExchange 实现延迟队列效果。



### 13. 如何保证消息队列的高可用？

==参考答案==

#### RabbitMQ 的高可用：

RabbitMQ 的集群模式有3种：**普通集群模式**、**镜像集群模式**和**仲裁队列模式**

- **普通集群模式**：不具备高可用性。集群的各个节点间共享集群的元数据，包括：交换机元数据、队列元信息，不包含队列中的消息。当访问集群某节点时，如果队列不在该节点，会从数据所在节点传递到当前节点并返回。队列所在节点宕机，队列中的消息就会丢失

  <img src="https://raw.githubusercontent.com/ayifuture0920/java-study/main/pictures/20201015111005952.png" alt="img" style="zoom: 80%;" />

- **镜像集群模式**：具备高可用性。本质是主从模式，集群元数据以及队列中的消息会在各个 MQ 的镜像节点之间同步备份。创建队列的节点被称为该队列的**主节点，**备份到的其它节点叫做该队列的**镜像**节点，一个队列的主节点可能是另一个队列的镜像节点。所有操作都是主节点完成，然后同步给镜像节点，主宕机后，镜像节点会替代成新的主节点。

  <img src="https://raw.githubusercontent.com/ayifuture0920/java-study/main/pictures/20201015111357877.png" alt="img" style="zoom:80%;" />

- **仲裁队列**：具有高可用性。裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征：与镜像队列一样，都是主从模式，支持主从数据同步。使用非常简单，没有复杂的配置。主从同步基于Raft协议，具有强一致性

### 14. 如何处理消息堆积情况?

==参考答案==

场景题：几千万条数据在MQ里积压了七八个小时。

#### 14.1、出现该问题的原因：

消息堆积往往是生产者的生产速度与消费者的消费速度不匹配导致的。有可能就是消费者消费能力弱，渐渐地消息就积压了；也有可能是因为消息消费失败不停重试造成的；也有可能是消费端出了问题，导致不消费了或者消费极其慢。*比如，消费端每次消费之后要写mysql，结果 mysql挂了，消费端hang住了不动了，或者消费者本地依赖的一个东西挂了，导致消费者挂了。*

所以如果是 bug 则处理 bug；如果是因为本身消费能力较弱，则优化消费逻辑，比如优化前是一条一条消息消费处理的，那么就可以批量处理进行优化。

#### 14.2、避免发生消息堆积：

- **队列上绑定多个消费者，提高消费速度**
- **扩大队列容积，提高堆积上限**：

将一个队列设置为**惰性队列**，只需要在声明队列时，指定`x-queue-mode: lazy`即可。将消息存入到磁盘，从而支持数百万条的消息存储，消费者要消费消息时才会从磁盘中读取并加载到内存。

#### 14.3 如何解决已经发生的消息堆积问题？

- **临时扩容，快速处理积压的消息**：

  （1）先修复 Consumer 的问题，确保其恢复消费速度，然后将现有的 Consumer 都停掉；

  （2）临时创建原先 N 倍数量的 queue ，然后写一个临时分发数据的消费者程序，将该程序部署上去消费队列中积压的数据，消费之后不做任何耗时处理，直接均匀轮询写入临时建立好的 N 倍数量的 queue 中；

  （3）接着，临时征用 N 倍的机器来部署 consumer，每个 consumer 消费一个临时 queue 的数据

  （4）等快速消费完积压数据之后，恢复原先部署架构 ，重新用原先的 consumer 机器消费消息。

- **恢复队列中丢失的数据**：

由于设置了 TTL，导致队列中很多消息因为超时而被丢弃，就不能只是增加 Consumer 消费积压的数据了，这种情况可以采取 ”**批量重导**” 的方案来进行解决。在流量低峰期，写一个程序，手动去查询丢失的那部分数据，然后将消息重新发送到mq里面，把丢失的数据重新补回来。

- **MQ长时间未处理导致MQ写满的情况如何处理**：

如果消息积压在MQ里，并且长时间都没处理掉，导致MQ都快写满了，这种情况肯定是临时扩容方案执行太慢，这种时候只好采用 “丢弃+批量重导” 的方式来解决了。首先，临时写个程序，连接到 MQ 里面消费数据，消费一个丢弃一个，快速消费掉积压的消息，降低MQ的压力，然后在流量低峰期时去手动查询重导丢失的这部分数据。



### 15. RabbitMQ是什么？

==参考答案==

RabbitMQ是实现了高级消息队列协议（`Advanced Message Queue Protocol(AMQP)`）的开源消息代理软件（亦称面向消息的中间件）。RabbitMQ服务器是用Erlang语言编写的，而群集和故障转移是构建在开放电信平台框架上的。所有主要的编程语言均有与代理接口通讯的客户端库。



